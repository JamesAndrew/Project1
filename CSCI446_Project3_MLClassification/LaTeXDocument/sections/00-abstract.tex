\begin{abstract} \label{abstract}
When determining how to best solve a given classification problem, it is important to understand the various tools available and what each is best suited for. 
In this paper, four different machine learning algorithms will be implemented and tested on five different data sets from the UCI Machine Learning Repository in order to determine what data attributes are best suited for which algorithms. 
The algorithms implemented are K-Nearest Neighbor(k-NN), Naive Bayes(NB), Tree Augmented Naive Bayes(TAN) and  Decision Tree Learning - Iterative Dichotomiser 3 (ID3). The data sets chosen are Breast-Cancer-Wisconsin, Glass, House-Votes-84, Iris and Soybean. All data sets were pre-processed to provide uniform formatting, fill in missing values and discretize any continuous data. 

After implementing all algorithms it was determined that, as expected, there is not one solution that will be best at all classification problems and instead, the solution must be chosen after careful evaluation of the data. For the k-NN algorithm, size and number of attributes were found to have the least amount of influence when compared to the other algorithms and performance relied mainly on how linearly separable the classes are. Both of the Bayes algorithms were found to do best with a combination of large point numbers and fewer unique attribute values while the ID3 algorithm, though perhaps the most consistent performer, favored the data sets with the most features for its best results. 

\end{abstract}